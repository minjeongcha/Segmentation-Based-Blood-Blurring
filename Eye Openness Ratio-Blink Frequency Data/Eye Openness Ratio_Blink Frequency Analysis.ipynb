{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe7aa7b-1a92-4dec-970a-916e29dcc36e",
   "metadata": {},
   "source": [
    "## <B>Calibrate EAR data</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0a52b-b5bc-4cde-ade6-f365142c2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Variables to use for filenames\n",
    "name = \"37\"\n",
    "\n",
    "# List of movie names\n",
    "movies = [\"기생충1\", \"기생충2\", \"낭닥1\", \"낭닥2\", \"코1\", \"코2\", \"마녀1\", \"마녀2\", \"레버1\", \"레버2\"]\n",
    "\n",
    "# Processing data by file\n",
    "for movie in movies:\n",
    "    # Create a file path\n",
    "    file = f'{name} {movie} 보정.csv'\n",
    "    \n",
    "    # Read a file\n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "    # Convert timestamp to seconds\n",
    "    def convert_to_seconds(timestamp):\n",
    "        minutes, seconds = map(float, timestamp.split(\":\"))\n",
    "        return minutes * 60 + seconds\n",
    "\n",
    "    data['Seconds'] = data['Timestamp'].apply(convert_to_seconds)\n",
    "    \n",
    "    # Group by 0.1 second interval\n",
    "    data['Time_Group'] = (data['Seconds'] * 10).astype(int) / 10\n",
    "    \n",
    "    # Calculate EAR averages at 0.1 second intervals\n",
    "    result = data.groupby('Time_Group')['EAR'].mean().reset_index()\n",
    "    \n",
    "    # Save the results\n",
    "    output_file = f'{name} {movie} 평균_EAR.csv'\n",
    "    result.to_csv(output_file, index=False)\n",
    "    print(f\"Processed: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b119a0-afb9-4cb2-a661-4c2e98dd1945",
   "metadata": {},
   "source": [
    "## <B>EAR data calibration (for special cases of time data)</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3a296-256c-4dcc-9171-c1c56004e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File name\n",
    "file = \"37 낭닥1 보정.csv\"\n",
    "\n",
    "# Convert to seconds function (automatic calculation based on first time)\n",
    "def convert_to_seconds_with_auto_start(timestamp, initial_time):\n",
    "    initial_minutes, initial_seconds = map(float, initial_time.split(\":\"))\n",
    "    initial_total_seconds = initial_minutes * 60 + initial_seconds\n",
    "\n",
    "    current_minutes, current_seconds = map(float, timestamp.split(\":\"))\n",
    "    current_total_seconds = current_minutes * 60 + current_seconds\n",
    "\n",
    "    # Handling boundary crossings (current_total_seconds < initial_total_seconds)\n",
    "    if current_total_seconds < initial_total_seconds % 3600:\n",
    "        current_total_seconds += 3600  # 1시간 추가\n",
    "\n",
    "    return current_total_seconds\n",
    "\n",
    "# Read a file\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "# Handling exceptions when data is empty\n",
    "if data.empty:\n",
    "    print(f\"Empty file: {file}\")\n",
    "else:\n",
    "    # Set the initial time based on the first time value\n",
    "    initial_time = data['Timestamp'].iloc[0]\n",
    "\n",
    "    # Add a ‘Seconds’ column\n",
    "    data['Seconds'] = data['Timestamp'].apply(lambda t: convert_to_seconds_with_auto_start(t, initial_time))\n",
    "\n",
    "    # Group by 0.1 second interval\n",
    "    data['Time_Group'] = (data['Seconds'] * 10).astype(int) / 10\n",
    "\n",
    "    # Calculate EAR averages at 0.1 second intervals\n",
    "    result = data.groupby('Time_Group')['EAR'].mean().reset_index()\n",
    "\n",
    "    # Save the results\n",
    "    output_file = \"37 낭닥1 평균_EAR.csv\"\n",
    "    result.to_csv(output_file, index=False)\n",
    "    print(f\"Processed: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703cd02-67b9-4afa-a9aa-b56e9f9fcd4d",
   "metadata": {},
   "source": [
    "## <B>Eye Openness Ratio During Gory Video Viewing Analysis</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656c695-2165-45d7-a3e9-5fc67eecc184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "name = \"37\"\n",
    "\n",
    "movies = [\"기생충\", \"낭닥\", \"코\", \"마녀\", \"레버\"]\n",
    "\n",
    "for movie in movies:\n",
    "    data1 = pd.read_csv(f'{name} {movie}1 평균_EAR.csv')\n",
    "    data2 = pd.read_csv(f'{name} {movie}2 평균_EAR.csv')\n",
    "\n",
    "    count_data3 = data1['EAR'].mean()\n",
    "    count_data4 = data2['EAR'].mean()\n",
    "\n",
    "    max_data1 = data1['EAR'].max()\n",
    "    min_data1 = data1['EAR'].min()\n",
    "    \n",
    "    max_data2 = data2['EAR'].max()\n",
    "    min_data2 = data2['EAR'].min()\n",
    "\n",
    "    # EAR normalization\n",
    "    normalized_data1 = (data1['EAR'] / max_data1) * 100\n",
    "    normalized_data2 = (data2['EAR'] / max_data2) * 100\n",
    "\n",
    "    normalized_mean_data1 = normalized_data1.mean()\n",
    "    normalized_mean_data2 = normalized_data2.mean()\n",
    "\n",
    "    print(f\"EAR average in data1.csv: {count_data3}\")\n",
    "    print(f\"EAR average in data2.csv: {count_data4}\")\n",
    "    print(f\"EAR maximum for data1.csv: {max_data1}\")\n",
    "    print(f\"EAR minimum for data1.csv: {min_data1}\")\n",
    "    print(f\"EAR maximums in data2.csv: {max_data2}\")\n",
    "    print(f\"EAR minimums in data2.csv: {min_data2}\")\n",
    "    print(f\"EAR average of normalized data1.csv: {normalized_mean_data1}\")\n",
    "    print(f\"EAR average for normalized data2.csv: {normalized_mean_data2}\")\n",
    "    print(\"---------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192708ce-0642-467d-9592-7d2ceff50781",
   "metadata": {},
   "source": [
    "## <B>Blink Frequency Analysis</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dfb81-b0a3-4183-8722-cc53a39a5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "name = \"37\"\n",
    "\n",
    "movies = [\"기생충\", \"낭닥\", \"코\", \"마녀\", \"레버\"]\n",
    "\n",
    "for movie in movies:\n",
    "    data1 = pd.read_csv(f'{name} {movie}1 평균_EAR.csv')\n",
    "    data2 = pd.read_csv(f'{name} {movie}2 평균_EAR.csv')\n",
    "\n",
    "    # EAR normalization\n",
    "    max_data1 = data1['EAR'].max()\n",
    "    min_data1 = data1['EAR'].min()\n",
    "    \n",
    "    max_data2 = data2['EAR'].max()\n",
    "    min_data2 = data2['EAR'].min()\n",
    "\n",
    "    data1['Normalized EAR'] = ((data1['EAR'] - min_data1) / (max_data1 - min_data1)) * 100\n",
    "    data2['Normalized EAR'] = ((data2['EAR'] - min_data2) / (max_data2 - min_data2)) * 100\n",
    "\n",
    "    data1['EAR 0/1'] = (data1['EAR'] >= 0.25).astype(int)\n",
    "    data2['EAR 0/1'] = (data2['EAR'] >= 0.25).astype(int)\n",
    "\n",
    "    # Count the instant of change from 0 to 1\n",
    "    data1['Transition Count'] = ((data1['EAR 0/1'].shift(1) == 0) & (data1['EAR 0/1'] == 1)).astype(int)\n",
    "    data2['Transition Count'] = ((data2['EAR 0/1'].shift(1) == 0) & (data2['EAR 0/1'] == 1)).astype(int)\n",
    "\n",
    "    count_transitions_data1 = data1['Transition Count'].sum()\n",
    "    count_transitions_data2 = data2['Transition Count'].sum()\n",
    "\n",
    "    print(f\"Count the instantaneous 0 to 1 transitions in data1.csv: {count_transitions_data1}\")\n",
    "    print(f\"Count the instantaneous 0 to 1 transitions in data2.csv: {count_transitions_data2}\")\n",
    "    print(\"---------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
