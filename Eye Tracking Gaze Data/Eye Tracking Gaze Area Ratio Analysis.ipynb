{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cd191f-5d50-4e23-94e7-f482288f3a5b",
   "metadata": {},
   "source": [
    "## <B>Normalize Gaze Coordinate Data</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df881d-d4ec-4ad0-80ed-74b13bb53532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "name = \"37\"\n",
    "\n",
    "movies = [\"기생충1\", \"기생충2\", \"낭닥1\", \"낭닥2\", \"코1\", \"코2\",  \"마녀1\", \"마녀2\", \"레버1\", \"레버2\"]\n",
    "\n",
    "for movie in movies:\n",
    "    # 데이터 파일 불러오기\n",
    "    # 파일명: 영상_좌표_보정.csv\n",
    "    data = pd.read_csv(f'{name} {movie}.csv')\n",
    "    \n",
    "    # 열 이름 확인 및 공백 제거\n",
    "    data.columns = data.columns.str.strip()  # 열 이름의 불필요한 공백 제거\n",
    "    \n",
    "    # X와 Y 컬럼 확인\n",
    "    print(\"원본 데이터:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Min-Max Scaler를 사용하여 정규화 (범위: -1에서 1)\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    \n",
    "    # X와 Y를 정규화\n",
    "    data[['X', 'Y']] = scaler.fit_transform(data[['X', 'Y']])\n",
    "    \n",
    "    # 결과 확인\n",
    "    print(\"\\n정규화된 데이터:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # 정규화된 데이터를 새로운 CSV 파일로 저장\n",
    "    data.to_csv(f'{name} {movie}(정규화).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416014e3-32ef-4440-b4c5-c57a0136fc5d",
   "metadata": {},
   "source": [
    "## <B>Presence of eyes in blurred areas of experimental footage O/X</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3455f0-cdb6-4621-8ecb-118bda301547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# 경고를 무시하도록 설정\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# OX 분석 및 통합 처리 함수 정의\n",
    "def process_and_analyze(name, movie, box_file):\n",
    "    try:\n",
    "        # 데이터 읽기\n",
    "        points_df = pd.read_csv(f'{name} {movie}(정규화).csv')  # 정규화된 점 데이터\n",
    "        boxes_df = pd.read_csv(box_file)  # 박스 데이터\n",
    "\n",
    "        # Timestamp 변환 및 초기화\n",
    "        points_df['Timestamp (Current Time)'] = pd.to_datetime(points_df['Timestamp (Current Time)'], errors='coerce')\n",
    "        points_df.dropna(subset=['Timestamp (Current Time)'], inplace=True)  # NaT 삭제\n",
    "\n",
    "        # 기준 시간 설정 및 초 단위 변환\n",
    "        base_time = points_df['Timestamp (Current Time)'].iloc[0]\n",
    "        points_df['Time (seconds)'] = (points_df['Timestamp (Current Time)'] - base_time).dt.total_seconds()\n",
    "\n",
    "        # 시간 값 반올림 및 중복 제거\n",
    "        points_df['Time (seconds)'] = points_df['Time (seconds)'].round(1)\n",
    "        boxes_df['Time (seconds)'] = boxes_df['Time (seconds)'].round(1)\n",
    "        points_df = points_df.drop_duplicates(subset='Time (seconds)', keep='first')\n",
    "        boxes_df = boxes_df.drop_duplicates(subset='Time (seconds)', keep='first')\n",
    "\n",
    "        # 시간 기준 병합\n",
    "        merged_df = pd.merge(boxes_df, points_df, how='left', on='Time (seconds)')\n",
    "        merged_df.to_csv(f'{name}_{movie}_merged.csv', index=False)  # 병합 결과 저장\n",
    "\n",
    "        # OX 결과 계산\n",
    "        def point_box_with_margin(row):\n",
    "            expanded_x1 = row['x1'] - 0.25\n",
    "            expanded_y1 = row['y1'] - 0.25\n",
    "            expanded_x2 = row['x2'] + 0.25\n",
    "            expanded_y2 = row['y2'] + 0.25\n",
    "            return \"O\" if expanded_x1 <= row['X'] <= expanded_x2 and expanded_y1 <= row['Y'] <= expanded_y2 else \"X\"\n",
    "\n",
    "        merged_df['Result'] = merged_df.apply(point_box_with_margin, axis=1)\n",
    "\n",
    "        # O 비율 계산 및 출력\n",
    "        o_count = merged_df['Result'].value_counts().get('O', 0)\n",
    "        total_count = len(merged_df)\n",
    "        o_ratio = o_count / total_count if total_count > 0 else 0\n",
    "\n",
    "        print(f'\"{movie}\" 분석 결과:')\n",
    "        print(f'  \"O\"의 개수: {o_count}')\n",
    "        print(f'  \"O\"의 비율: {o_ratio:.2%}')\n",
    "\n",
    "        # 최종 결과 저장\n",
    "        merged_df.to_csv(f'{name} {movie}_result.csv', index=False)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"파일을 찾을 수 없습니다: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "\n",
    "# 실행 예시\n",
    "name = \"37\"\n",
    "movie_box_map = {\n",
    "    \"기생충1\": \"영화1 보정.csv\",\n",
    "    \"기생충2\": \"영화1 보정.csv\",\n",
    "    \"낭닥1\": \"영화2 보정.csv\",\n",
    "    \"낭닥2\": \"영화2 보정.csv\",\n",
    "    \"코1\": \"영화3 보정.csv\",\n",
    "    \"코2\": \"영화3 보정.csv\",\n",
    "    \"마녀1\": \"영화4 보정.csv\",\n",
    "    \"마녀2\": \"영화4 보정.csv\",\n",
    "    \"레버1\": \"영화5 보정.csv\",\n",
    "    \"레버2\": \"영화5 보정.csv\",\n",
    "}\n",
    "\n",
    "for movie, box_file in movie_box_map.items():\n",
    "    process_and_analyze(name, movie, box_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
